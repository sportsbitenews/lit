Bias in Online Marketplaces
===========================

Bias is an inherent part of human nature. Homophily {{"mcpherson2001birds" | cite}}.

Before the existence of online exchange markets, researchers have observed bias in labor markets. In 2004, Lavergne and Mullainathan {{"lavergne2004emily" | cite}}.

What pre-dates the online marketplaces for physical resources exchange, online knowledge and collaboration platforms, bias has been observed. Gender in open source community {{"vasilescu2012gender" | cite}}

The lack of visual cues of online marketplaces may even exacerbated the problem of bias. Following exactly the same field experiment setup, in 2015, Edelman et al., also at Havard Business School, conducted the experiment on Airbnb. It showed that ethnic discrimination persists in this prominent online marketplace for lodging {{"edelman2017racial" | cite}}. Evidence from other studies on freelance marketplaces (TaskRabbit, Friverr) {{"hannak2017bias" | cite}}. Self-representation, the host profiles {{"ma2017self" | cite}}. Creates polity issues {{"levy2017designing" | cite}}.

In addition to ethnic discrimination, other potential sources of bias arise from status, including contextually induced status as in the case of couchsurfing, and social economic status.

2016 Couch surfing {{"bogdan2016power" | cite}}, status causes bias in review systems. Gender {{"hannak2017bias" | cite}}. Geographically induced social economic status {{"thebault2017toward" | cite}}.

Finally, we discuss the problem of algorithmic bias in online marketplaces. Due to the scale of the marketplace, recommendation systems are an important feature to allow people to discover potential exchange partners. Horton showed that when employeers were offered algorithmic recommendations, a large portion followed and that "experimentally induced recruits were highly positively selected and were statistically indistinguishable from the kinds of workers employers recruit 'on their own.'" {{"horton2017effects" | cite}}. What's complicated in these types of systems that decide to surface exchange partners is that the algorithms making the decisions are inherently opaque, and may pick up factors such as gender or race as a result of biased training data. The algorithmic bias in recommendation systems is an example of the broader bias in the context of quickly advancing AI and its impact on societal change, [systems used to rank teachers, decides who gets a loan or parole](https://www.technologyreview.com/s/608248/biased-algorithms-are-everywhere-and-no-one-seems-to-care/).

This brings us to the question, what's the solution to the algorithmic bias. One approach is to algorithmic approaches to solve the problem {{"hardt2016equality"| cite}}. Another approach is the collaboration between researchers across different disciplines, industry initiatives such as [Google People+AI Research Initiative (PAIR)](https://ai.google/pair/), and [AI Now Institute](https://ainowinstitute.org/).

References
----------

{% references %} {% endreferences %}
